---
title: "Lecture 6 Code"
author: "Alex Hoagland"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r header,echo=FALSE, results='hide'}
library(tidyverse)
library(wooldridge)
library(pwr)
library(pwrss)
```

## Simple hypothesis test: One mean

Let's start with defining the test procedure for a simple mean. We will use the Wooldridge `wagepan` data set.

```{r simple-test}
# Load the Wooldridge wag2 data
mydata <- wooldridge::wagepan

summary(mydata) # What are we looking at? 

# One thing: this is a panel, so we have repeated observations per person. Let's just look at 1985 data for a bit
testdata <- mydata %>% filter(year==1985) # filter for 1985 data

# Let's describe wages
testdata %>% mutate(wage = exp(lwage)) %>% # convert to dollars
  ggplot() + geom_histogram(aes(wage),
                            binwidth=1,fill='skyblue',color='black',alpha=.8) +
  theme_classic() + 
  geom_vline(xintercept=5.9192, color="red", linetype="dashed") +
    # line for average wage in sample
  labs(x="Hourly Wages", y="") # plot the distribution of wages

# What do we see here? 

# Let's test the hypothesis that the average wage is $7.77 (average hourly wage in USD, 1985)
  # First, what's the null here? Why did we choose it? 
  # What's the test statistic?
  mean(exp(testdata$lwage)) # average wage is $6.47 in sample
  sd(exp(testdata$lwage)) # SD is 3.89
  (mean(exp(testdata$lwage))-7.77)/(sd(exp(testdata$lwage))/sqrt(nrow(testdata))) 
    # t-statistic (how do we interpret this?)

  t.test(exp(testdata$lwage), mu=7.77) # What do we think? Ignore p-value for now

  # What's the conclusion? How do we interpret our test? 
  
  # What if we want to do a one-sided vs. two-sided test.
  t.test(exp(testdata$lwage), mu=7.77, alternative = "two.sided")
  t.test(exp(testdata$lwage), mu=7.77, alternative = "less")
  t.test(exp(testdata$lwage), mu=7.77, alternative = "greater") # what does this mean here? 
```

Remember that as we discussed last time, we can also use `wilcox.test` to test the median of a distribution rather than the mean. 

```{r simple-test}
# Let's test the hypothesis that the median wage is $6.03 (median hourly wage in USD, 1985)
median(exp(testdata$lwage)) # median wage is $5.85 in sample
wilcox.test(exp(testdata$lwage), mu=6.03, conf.int=TRUE) # What do we think? Ignore p-value for now) 
```

## What about a test for proportions? 
To keep things simple, let's just test if our sample is nationally representative of the US population in terms of union membership. in 1980, roughly 8.7% of the US workforce was unionized. 

```{r prop-test-union}
mean(testdata$union) # 22% in unions in 1985
prop.test(sum(testdata$union),nrow(testdata), p=0.087)

# What if we want to do a one-sided vs. two-sided test.
prop.test(sum(testdata$union),nrow(testdata), p=0.087, alternative = "two.sided")
prop.test(sum(testdata$union),nrow(testdata), p=0.087, alternative = "greater") 
```
We can also chat here about how to store and recover objects from our test: 

```{r storing-test-objects}
mytest <- prop.test(sum(testdata$union),nrow(testdata), p=0.087, alternative = "two.sided")
mytest$estimate
mytest$statistic
mytest$conf.int
mytest$p.value
```

## Testing difference in means

Okay, now suppose we want to test difference in wages across groups. Let's look at two comparisons: black/non-black and health status.

```{r test-differences}
# First, let's compare black/non-black. 
# Make a bar chart showing size of black and non-black groups in testdata
testdata %>% ggplot() + geom_bar(aes(black), fill='palegreen2',color='black',alpha=.8) +
  theme_classic() + labs(x="Black", y="Count") 
summary(testdata$black) # What do we make of this? 

# Now make a two-way histogram for exp(lwage) across black and non-black in testdata
testdata %>% mutate(wage = exp(lwage)) %>% ggplot() + geom_histogram(aes(wage,fill=as.factor(black)),                           binwidth=1,position="dodge",color='black',alpha=.8) +
  theme_classic() + labs(x="Hourly Wages", y="",fill="Black") + facet_wrap(~black) # plot the distribution of wages

# Now let's test the difference in wages across black and non-black
  # First, what's the null here? Why did we choose it? 
  # What's the test statistic?
  mean1 <- mean(exp(testdata[which(testdata$black==0),]$lwage)) # 
  mean2 <- mean(exp(testdata[which(testdata$black==1),]$lwage)) #
  sd1 <- sd(exp(testdata[which(testdata$black==0),]$lwage)) # 
  sd2 <- sd(exp(testdata[which(testdata$black==1),]$lwage)) #
  (mean1-mean2)/sqrt(sd1^2/nrow(testdata[which(testdata$black==0),]) + sd2^2/nrow(testdata[which(testdata$black==1),])) # t-statistic (how do we interpret this?)
t.test(exp(testdata$lwage) ~ testdata$black, alternative="greater") # What do we think? What should the default be?
t.test(exp(testdata$lwage) ~ testdata$black, alternative="two.sided") # What do we think?

# What if we do the same thing for poor health instead of black? 
# Make a bar chart showing size of groups
testdata %>% ggplot() + geom_bar(aes(poorhlth), fill='royalblue4',color='black',alpha=.8) +
  theme_classic() + labs(x="Poor Health", y="Count") 
summary(testdata$poorhlth) # What do we make of this? 

# Now make a two-way histogram for exp(lwage) across groups
testdata %>% mutate(wage = exp(lwage)) %>% ggplot() + geom_histogram(aes(wage,fill=as.factor(poorhlth)),                           binwidth=1,position="dodge",color='black',alpha=.8) +
  theme_classic() + labs(x="Hourly Wages", y="",fill="Poor Health") + facet_wrap(~poorhlth) # plot the distribution of wages

# Now let's test the difference in wages across groups
  # First, what's the null here? Why did we choose it? 
  # What's the test statistic?
t.test(exp(testdata$lwage) ~ testdata$poorhlth, conf.level=0.90) # What do we think?
t.test(exp(testdata$lwage) ~ testdata$poorhlth, conf.level=0.90, alternative = "greater") # notice what this does to the confidence interval
```

## Other two-sample tests
We can also do this for proportions and means. 

```{r two-sample test}
# Let's test the difference in union membership across black and non-black
prop.table(table(testdata$black, testdata$union), margin=1) # What do we make of this?
prop.test(table(testdata$black, testdata$union), correct=TRUE) # What do we think?
```

## How do tests depend on variance assumptions? 
There are three big categories of a two-sample test: pooled variance, unequal variances, and matched samples. Let's look at each of these in the context of union membership across US geographic regions:

```{r two-sample-test-variance}
# These test the first two categories
t.test(testdata$union~testdata$nrtheast, var.equal = TRUE)
t.test(testdata$union~testdata$nrtheast, var.equal = FALSE)

# Matched data is a bit different, and requires a different structure to the data 
# Let's look at the same individual over time and test that wages were stagnant in real dollars
matchedata <- mydata %>% filter(year %in% c(1980, 1987)) %>% 
  mutate(wage = exp(lwage)) %>% 
  mutate(wage = ifelse(year == 1980, wage*3.83, wage*2.78)) %>% # adjust for inflation
  select(nr, year, wage) %>%
  spread(year, wage) # spread the data to wide format 

# Now we can test with a matched sample
names(matchedata) <- c("nr", "w1980", "w1987")
matchedata <- matchedata %>% mutate(diff = w1987-w1980)
t.test(matchedata$w1980, matchedata$w1987, paired = TRUE)
hist(matchedata$diff) # are we suprised by the result? 
t.test(matchedata$diff)
```

## Categorical Variables
Let's do some $\chi^2$-testing for categorical variables. We can use the `exper` and `occ*` variables which measure years of experience and occupational categories

```{r chi2-test}
# Do minority workers sort into different occupations? 

# First, build a variable that measures occupation 
testdata <- testdata %>% mutate(allocc = ifelse(occ1 == 1, 1, 
                                                ifelse(occ2 == 1, 2, 
                                                       ifelse(occ3 == 1, 3, 
                                                              ifelse(occ4 == 1, 4, 
                                                                     ifelse(occ5 == 1, 5, 
                                                                            ifelse(occ6 == 1, 6, 
                                                                                   ifelse(occ7 == 1, 7, 8))))))))
hist(testdata$allocc)

# Now make a two-way histogram across black and non-black in testdata
testdata %>% ggplot(aes(x=allocc)) + 
  geom_histogram(aes(y = (..count..)/sum(..count..),fill=as.factor(black)), 
                 binwidth=1,position="dodge",color='black',alpha=.8) +
  theme_classic() + labs(x="Occupation Codes", y="",fill="Black") + 
  facet_wrap(~black) # plot the distribution of wages

# Let's do a formal test if these follow the same distribution
chisq.test(table(testdata$black, testdata$allocc)) # What do we think? 

# What's actually informative here? Do we care if the distribution is different? What do we care about? 
t.test(testdata$agric ~ testdata$black) # This is more easily interpretable. 
```

So when might we use a $\chi^2$ test? Maybe when we want to see if a variable follows a specific distribution

```{r chi2-test-2}
# Let's test if the distribution of occupations is different from a uniform distribution
chisq.test(table(testdata$allocc)) # What do we think?

# Can we test if the distribution of exper is different from a log-normal distribution?
library(EnvStats)
EnvStats::gofTest(testdata$exper, distname = "lnorm") # What do we think?
```

You can also test if two categorical variables are independent (this is often quite useful)!

```{r test-independence}
# Let's test if union membership is independent of some demographics
# Here the null hypothesis is that the two variables are *independent*
chisq.test(table(testdata$union, testdata$poorhlth)) # What do we think? 
chisq.test(table(testdata$union, testdata$black)) # What do we think? 
```

## Examining rejection regions
Let's look more carefully at rejection regions 

```{r rejection-regions}
area_poly <- function(cur, cutoff, side=c(1,-1), col = "grey", border=NA, ...)
{
  if (side[1]>0 )# on the right
  {
    pos <- min(which(cur$x > cutoff))
    end <- length(cur$x)
  }
  else # on the left
  {
    pos <- max(which(cur$x < cutoff))
    end <- 1
  }
  polygon(x=c(cur$x[end:pos], cur$x[pos], cur$x[end]),
          y=c(cur$y[end:pos], 0, 0), col=col, border=border, ...)
}

# Assign the curve cc (here, we don't yet standardize)
cc <- curve(dnorm(x, mean = 20, sd = 10), from = -10, to = 50, n = 1000, lwd = 3, xlab = "", ylab = "Density", frame = F)
area_poly(cc, cutoff = 16, side = 1, col = "grey50", density = 10)

# What if we standardize?
cc <- curve(dnorm(x, mean = 0, sd = 1), from = -4.2, to = 4.2, n = 1000, lwd = 3, xlab = "", ylab = "Density", frame = F)
area_poly(cc, cutoff = -.4, side = 1, col = "grey50", density = 10)

# But we haven't yet adjusted for standard error!
cc <- curve(dnorm(x, mean = 0, sd = 1), from = -4, to = 4, n = 1000, lwd = 3, xlab = "", ylab = "Density", frame = F)
area_poly(cc, cutoff = -.4*sqrt(100), side = 1, col = "grey50", density = 10)
```

Specifically, we have to decide if we want a one-sided or a two-sided test. 

``` {r one-two-sided-test}
# What about a two-sided test? 
# plot the standard normal density on the interval [-4,4]
curve(dnorm(x),
      xlim = c(-4, 4),
      main = 'Calculating a p-Value',
      yaxs = 'i',
      xlab = 'z',
      ylab = '',
      lwd = 2,
      axes = 'F')

# add x-axis
axis(1, 
     at = c(-1.5, 0, 1.5), 
     padj = 0.75,
     labels = c(expression(-frac(bar(x)~-~bar(mu)[x,0], sigma[bar(x)])),
                0,
                expression(frac(bar(x)~-~bar(mu)[x,0], sigma[bar(x)]))))

# shade p-value/2 region in left tail
polygon(x = c(-6, seq(-6, -1.5, 0.01), -1.5),
        y = c(0, dnorm(seq(-6, -1.5, 0.01)),0), 
        col = 'steelblue')

# shade p-value/2 region in right tail
polygon(x = c(1.5, seq(1.5, 6, 0.01), 6),
        y = c(0, dnorm(seq(1.5, 6, 0.01)), 0), 
        col = 'steelblue')

# What about a ONE-sided test? 
# plot the standard normal density on the interval [-4,4]
curve(dnorm(x),
      xlim = c(-4, 4),
      main = 'Calculating a p-Value',
      yaxs = 'i',
      xlab = 'z',
      ylab = '',
      lwd = 2,
      axes = 'F')

# add x-axis
axis(1, 
     at = c(-.5, 0.5), 
     padj = 0.75,
     labels = c(expression(-frac(bar(x)~-~bar(mu)[x,0], sigma[bar(x)])),
                0))

# shade p-value region all in left tail
polygon(x = c(-6, seq(-6, -.5, 0.01), -.5),
        y = c(0, dnorm(seq(-6, -.5, 0.01)),0), 
        col = 'steelblue')
```

### Why can we use the CLT here? 
The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean is approximately normally distributed, regardless of the distribution of the underlying population, as long as the sample size is sufficiently large.

Importantly, the test statistic here also follows a standard normal as the sample size increases. We can show this through simulating. 

```{r simulation-t}
# prepare empty vector for t-statistics
tstatistics <- numeric(10000)

# set sample size
n <- 300 # play around with this parameter

# simulate 10000 t-statistics
for (i in 1:10000) {
  
  s <- sample(0:1, 
              size = n,  
              prob = c(0.9, 0.1),
              replace = T)
  
  tstatistics[i] <- (mean(s)-0.1)/sqrt(var(s)/n)
  
}

# plot density and compare to N(0,1) density
plot(density(tstatistics),
     xlab = 't-statistic',
     main = 'Estimated Distribution of the t-statistic when n=300',
     lwd = 2,
     xlim = c(-4, 4),
     col = 'steelblue')

# N(0,1) density (dashed)
curve(dnorm(x), 
      add = T, 
      lty = 2, 
      lwd = 2) # so think carefully -- what is the distribution we're showing here? 
```

## P-values
Let's go back to the example from last time about tipping and think about the p-values here. 

```{r small-n-tests-pvalues}

# sample data that has 16 observations with mean 12 and var 23
tip_data <- data.frame(rnorm(16, mean = 12, sd = sqrt(23)))
names(tip_data) <- "tips"

# can we reject the null hypothesis of mean = 15 with 99% confidence? 
t.test(tip_data, mu = 15, conf.level = 0.99)
confint(lm(tips~1,tip_data), level=0.99) # 99% confidence interval for tip_data

# Okay, suppose that we had a larger sample size of n=100
tip_data <- data.frame(rnorm(100, mean = 12, sd = sqrt(23)))
names(tip_data) <- "tips"
t.test(tip_data, mu = 15, conf.level = 0.99)
confint(lm(tips~1,tip_data), level=0.99) 

# What if variance changed too? 
tip_data <- data.frame(rnorm(100, mean = 12, sd = sqrt(100)))
names(tip_data) <- "tips"
t.test(tip_data, mu = 15, conf.level = 0.99)
confint(lm(tips~1,tip_data), level=0.99) 
```

### Distributions of P-values
We can show these simulations directly in R. 

```{r pvalue-sim-true}
# The null hypothesis is that the average is equal to 0
# We will simulate 10000 p-values under the null hypothesis
pvalues <- numeric(10000)
for (i in 1:10000) {
  sample <- rnorm(100,mean=0,sd=100)
  pvalues[i] <- t.test(sample, mu = 0)$p.value
}
hist(pvalues)
```

```{r pvalue-sim-false}
# The null hypothesis is that the average is equal to 0
# We will simulate 10000 p-values under a slightly false null hypothesis
pvalues <- numeric(10000)
for (i in 1:10000) {
  s <- rnorm(100,mean=10,sd=100)
  pvalues[i] <- t.test(s, mu = 0)$p.value
}
hist(pvalues)

# We will simulate 10000 p-values under a wildly false null hypothesis
pvalues <- numeric(10000)
for (i in 1:10000) {
  s <- rnorm(100,mean=100,sd=100)
  pvalues[i] <- t.test(s, mu = 0)$p.value
}
hist(pvalues)
```

### Relationship between p-values and sample size. 
Finally, let's show the relationship between p-values and sample size **for the same test**.

```{r pvalue-sim-samplesize}
# The null hypothesis is that the average is equal to 100
# We will construct data with a true mean of 101 and different sample sizes
makedata <- function(n=100) { 
  testdata <- data.frame(rnorm(n, mean = 101, sd = 10))
  names(testdata) <- "sample"
  return(testdata)
}
mydata <- makedata(10000)
hist(mydata$sample)

# Now let's look at how p-values vary with sample size
 t.test(makedata(25), mu = 100)$p.value
 t.test(makedata(100), mu = 100)$p.value
 t.test(makedata(400), mu = 100)$p.value
 t.test(makedata(900), mu = 100)$p.value
 t.test(makedata(2500), mu = 100)$p.value
 t.test(makedata(10000), mu = 100)$p.value
 t.test(makedata(1e7), mu = 100)$p.value # is it wild to think of having a million observations? 

```

## Power

### What is power? 
Let's visualize what we're talking about 

```{r power-calcs,warning=FALSE}
power.z.test(ncp = 0.5, # 1.96, # critical value (non-centrality parameter)
             alpha = 0.05, # pr(type 1 error)
             alternative = "not equal", # what kind of test?
             plot = TRUE)
```

### Power calculations visualized
We can visualize the statistical power we would need under different hypothesized correlations. 

```{r power-calcs-3}
# Plot sample size curves for detecting correlations of
# various sizes.

# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)

# power values
p <- seq(.4,.9,.1)
np <- length(p)

# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
  for (j in 1:nr){
    result <- pwr.r.test(n = NULL, r = r[j],
    sig.level = .05, power = p[i],
    alternative = "two.sided")
    samsize[j,i] <- ceiling(result$n)
  }
}

# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
  xlab="Correlation Coefficient (r)",
  ylab="Sample Size (n)" )

# add power curves
for (i in 1:np){
  lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}

# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
   col="grey89")
title("Sample Size Estimation for Correlation Studies\n
  Sig=0.05 (Two-tailed)")
legend("topright", title="Power",
as.character(p),
   fill=colors)
```

### Power calculations in R
How do we calculate power directly? 

```{r power-calcs-2}
# You must leave exactly one out of the following: 
#      n, d (effect size), power, and sig.level
# Note that d = difference in means divided by pooled standard deviation
pwr.t.test(n=NULL, d = 0.1, sig.level = 0.01, power = .9, 
           type = "two.sample", alternative = "two.sided")
```

## Package Citations

```{r, include=FALSE}
print("=============================Works Cited=============================")
loadedNamespaces() %>%
map(citation) %>%
print(style = "text") # Adds citations for each package to end of .rmd file

knitr::write_bib(file = 'packages.bib') # Constructs a citation file for all packages used in this lecture.

# DON'T FORGET TO CITE YOUR PACKAGES IN YOUR PAPERS/ASSIGNMENTS. 
```

Let's knit this file and save it!
